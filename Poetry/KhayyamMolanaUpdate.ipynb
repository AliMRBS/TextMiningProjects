{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('khayyammolana.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|برخیز بتا'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolaries = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '\\r',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '.',\n",
       " ':',\n",
       " '|',\n",
       " '\\xa0',\n",
       " '«',\n",
       " '»',\n",
       " '،',\n",
       " '؛',\n",
       " '؟',\n",
       " 'ء',\n",
       " 'آ',\n",
       " 'أ',\n",
       " 'ؤ',\n",
       " 'إ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'ث',\n",
       " 'ج',\n",
       " 'ح',\n",
       " 'خ',\n",
       " 'د',\n",
       " 'ذ',\n",
       " 'ر',\n",
       " 'ز',\n",
       " 'س',\n",
       " 'ش',\n",
       " 'ص',\n",
       " 'ض',\n",
       " 'ط',\n",
       " 'ظ',\n",
       " 'ع',\n",
       " 'غ',\n",
       " 'ـ',\n",
       " 'ف',\n",
       " 'ق',\n",
       " 'ل',\n",
       " 'م',\n",
       " 'ن',\n",
       " 'ه',\n",
       " 'و',\n",
       " 'ي',\n",
       " 'ً',\n",
       " 'ٌ',\n",
       " 'ٍ',\n",
       " 'َ',\n",
       " 'ُ',\n",
       " 'ِ',\n",
       " 'ّ',\n",
       " 'ْ',\n",
       " 'ٓ',\n",
       " 'ٔ',\n",
       " 'ٰ',\n",
       " 'ٱ',\n",
       " 'پ',\n",
       " 'چ',\n",
       " 'ژ',\n",
       " 'ک',\n",
       " 'گ',\n",
       " 'ۀ',\n",
       " 'ی',\n",
       " 'ۡ',\n",
       " '\\u200f']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabolaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {u:i for i, u in enumerate(vocabolaries)}\n",
    "index2char = np.array(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " '\\r': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '\"': 4,\n",
       " '.': 5,\n",
       " ':': 6,\n",
       " '|': 7,\n",
       " '\\xa0': 8,\n",
       " '«': 9,\n",
       " '»': 10,\n",
       " '،': 11,\n",
       " '؛': 12,\n",
       " '؟': 13,\n",
       " 'ء': 14,\n",
       " 'آ': 15,\n",
       " 'أ': 16,\n",
       " 'ؤ': 17,\n",
       " 'إ': 18,\n",
       " 'ئ': 19,\n",
       " 'ا': 20,\n",
       " 'ب': 21,\n",
       " 'ة': 22,\n",
       " 'ت': 23,\n",
       " 'ث': 24,\n",
       " 'ج': 25,\n",
       " 'ح': 26,\n",
       " 'خ': 27,\n",
       " 'د': 28,\n",
       " 'ذ': 29,\n",
       " 'ر': 30,\n",
       " 'ز': 31,\n",
       " 'س': 32,\n",
       " 'ش': 33,\n",
       " 'ص': 34,\n",
       " 'ض': 35,\n",
       " 'ط': 36,\n",
       " 'ظ': 37,\n",
       " 'ع': 38,\n",
       " 'غ': 39,\n",
       " 'ـ': 40,\n",
       " 'ف': 41,\n",
       " 'ق': 42,\n",
       " 'ل': 43,\n",
       " 'م': 44,\n",
       " 'ن': 45,\n",
       " 'ه': 46,\n",
       " 'و': 47,\n",
       " 'ي': 48,\n",
       " 'ً': 49,\n",
       " 'ٌ': 50,\n",
       " 'ٍ': 51,\n",
       " 'َ': 52,\n",
       " 'ُ': 53,\n",
       " 'ِ': 54,\n",
       " 'ّ': 55,\n",
       " 'ْ': 56,\n",
       " 'ٓ': 57,\n",
       " 'ٔ': 58,\n",
       " 'ٰ': 59,\n",
       " 'ٱ': 60,\n",
       " 'پ': 61,\n",
       " 'چ': 62,\n",
       " 'ژ': 63,\n",
       " 'ک': 64,\n",
       " 'گ': 65,\n",
       " 'ۀ': 66,\n",
       " 'ی': 67,\n",
       " 'ۡ': 68,\n",
       " '\\u200f': 69}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('\\r')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_integer = np.array([char2index[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 21, 30, ..., 44,  1,  0], shape=(476563,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "ب\n",
      "ر\n",
      "خ\n",
      "ی\n",
      "ز\n",
      " \n",
      "ب\n",
      "ت\n",
      "ا\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(101, drop_remainder=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> |برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش \n",
      "---> که کوزه ها کنند از گل ما\n",
      "|چون عهده نمی شود کسی فردا را\n",
      "|حالی خوش دار این دل پر سودا را\n",
      "|می نوش به \n",
      "---> ماهتاب ای ماه که ماه\n",
      "|بسیار بتابد و نیابد ما را\n",
      "|قرآن که مهین کلام خوانند آن را\n",
      "|گه گاه نه بر دوام\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(3):\n",
    "    print('--->', ''.join(index2char[i.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sit(batch):\n",
    "    input_text = batch[:-1]\n",
    "    target_text = batch[1:]\n",
    "    return input_text, target_text\n",
    "dataset = sequences.map(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش\n",
      "برخیز بتا بیا ز بهر دل ما\n",
      "|حل کن به جمال خویشتن مشکل ما\n",
      "|یک کوزه شراب تا به هم نوش کنیم\n",
      "|زآن پیش \n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(''.join(index2char[i[0].numpy()]))\n",
    "    print(''.join(index2char[i[1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.batch(64, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabolaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabolary_size = len(vocabolaries)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step\n",
      "[[ 0.00970264 -0.01839882  0.00388445 ... -0.00793354  0.00108997\n",
      "   0.00679773]\n",
      " [ 0.0045926  -0.01137484 -0.00508215 ... -0.00638043 -0.00175606\n",
      "   0.00092236]\n",
      " [ 0.01077413 -0.00790394  0.00195149 ... -0.00628281 -0.01318328\n",
      "   0.00034212]\n",
      " ...\n",
      " [ 0.01813973  0.00461157 -0.00334634 ... -0.01713279 -0.01017357\n",
      "   0.00250647]\n",
      " [ 0.00012701 -0.00398188  0.01510931 ... -0.0059436   0.00957258\n",
      "   0.01141557]\n",
      " [-0.0212269   0.01074433  0.0119169  ... -0.00751193 -0.00436388\n",
      "   0.01279578]]\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    output = model.predict(input_text)\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
       "array([[25],\n",
       "       [16],\n",
       "       [31],\n",
       "       [22],\n",
       "       [25],\n",
       "       [45],\n",
       "       [ 7],\n",
       "       [17],\n",
       "       [32],\n",
       "       [27],\n",
       "       [55],\n",
       "       [60],\n",
       "       [44],\n",
       "       [30],\n",
       "       [59],\n",
       "       [28],\n",
       "       [32],\n",
       "       [65],\n",
       "       [29],\n",
       "       [64],\n",
       "       [69],\n",
       "       [51],\n",
       "       [ 9],\n",
       "       [14],\n",
       "       [42],\n",
       "       [40],\n",
       "       [ 5],\n",
       "       [49],\n",
       "       [18],\n",
       "       [25],\n",
       "       [20],\n",
       "       [ 6],\n",
       "       [40],\n",
       "       [ 0],\n",
       "       [63],\n",
       "       [42],\n",
       "       [38],\n",
       "       [69],\n",
       "       [32],\n",
       "       [16],\n",
       "       [42],\n",
       "       [ 9],\n",
       "       [35],\n",
       "       [41],\n",
       "       [50],\n",
       "       [40],\n",
       "       [67],\n",
       "       [48],\n",
       "       [56],\n",
       "       [56],\n",
       "       [38],\n",
       "       [33],\n",
       "       [56],\n",
       "       [38],\n",
       "       [ 2],\n",
       "       [27],\n",
       "       [12],\n",
       "       [43],\n",
       "       [58],\n",
       "       [65],\n",
       "       [65],\n",
       "       [15],\n",
       "       [52],\n",
       "       [49],\n",
       "       [29],\n",
       "       [48],\n",
       "       [60],\n",
       "       [11],\n",
       "       [ 0],\n",
       "       [68],\n",
       "       [29],\n",
       "       [34],\n",
       "       [27],\n",
       "       [53],\n",
       "       [ 9],\n",
       "       [24],\n",
       "       [59],\n",
       "       [12],\n",
       "       [66],\n",
       "       [37],\n",
       "       [68],\n",
       "       [67],\n",
       "       [ 1],\n",
       "       [44],\n",
       "       [26],\n",
       "       [22],\n",
       "       [34],\n",
       "       [51],\n",
       "       [68],\n",
       "       [39],\n",
       "       [15],\n",
       "       [15],\n",
       "       [39],\n",
       "       [21],\n",
       "       [56],\n",
       "       [28],\n",
       "       [20],\n",
       "       [16],\n",
       "       [33],\n",
       "       [44]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si = tf.random.categorical(output[0], num_samples=1)\n",
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 16, 31, 22, 25, 45,  7, 17, 32, 27, 55, 60, 44, 30, 59, 28, 32,\n",
       "       65, 29, 64, 69, 51,  9, 14, 42, 40,  5, 49, 18, 25, 20,  6, 40,  0,\n",
       "       63, 42, 38, 69, 32, 16, 42,  9, 35, 41, 50, 40, 67, 48, 56, 56, 38,\n",
       "       33, 56, 38,  2, 27, 12, 43, 58, 65, 65, 15, 52, 49, 29, 48, 60, 11,\n",
       "        0, 68, 29, 34, 27, 53,  9, 24, 59, 12, 66, 37, 68, 67,  1, 44, 26,\n",
       "       22, 34, 51, 68, 39, 15, 15, 39, 21, 56, 28, 20, 16, 33, 44])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(si, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'جأزةجن|ؤسخّٱمرٰدسگذک\\u200fٍ«ءقـ.ًإجا:ـ\\nژقع\\u200fسأق«ضفٌـیيْْعشْع خ؛لٔگگآًَذيٱ،\\nۡذصخُ«ثٰ؛ۀظۡی\\rمحةصٍۡغآآغبْداأشم'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[tf.squeeze(si, axis=-1).numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.44888499e-03,  1.11714844e-02,  6.47663930e-03,  9.44418274e-03,\n",
       "       -7.54784467e-03, -3.63717368e-03, -1.14993555e-02,  7.40472367e-03,\n",
       "       -1.13251116e-02, -2.98008230e-03, -9.63390153e-03,  5.49731497e-03,\n",
       "        3.09667340e-03, -7.55351502e-03,  2.44723260e-03, -1.21576563e-02,\n",
       "       -1.60848070e-03,  1.57391708e-02, -6.40200870e-03, -1.44026373e-02,\n",
       "       -4.29360196e-04,  5.34749543e-03,  5.39186411e-04,  1.43774934e-02,\n",
       "       -1.46316225e-02, -2.99174944e-03,  1.09978244e-02,  2.35257624e-03,\n",
       "        2.87530501e-03, -1.02336779e-02,  1.88457742e-02,  2.88052927e-03,\n",
       "       -9.23661981e-03,  9.77088977e-03,  7.03654904e-03, -7.07607251e-03,\n",
       "        8.46801046e-03,  1.85479969e-03, -1.80518988e-03,  5.10771666e-03,\n",
       "        3.51741863e-03, -8.59439187e-03,  7.60383578e-03,  2.19827588e-03,\n",
       "       -3.80006531e-06,  6.12420309e-03, -1.11474958e-03, -2.96268379e-03,\n",
       "        3.31144454e-03,  4.69873706e-03,  1.15257939e-02, -1.00553706e-02,\n",
       "        3.29412520e-04, -5.42816240e-04,  8.94447044e-03, -1.02306027e-02,\n",
       "        1.07701840e-02,  2.62494665e-03,  1.97587516e-02, -5.84758958e-03,\n",
       "       -1.50719867e-03, -4.29891329e-03, -8.54173116e-03,  2.39059655e-03,\n",
       "        6.77530514e-03,  2.64473842e-04, -8.73207394e-03, -3.50408442e-03,\n",
       "        2.50498671e-03,  1.68634690e-02], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,750</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m17,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m70\u001b[0m)          │        \u001b[38;5;34m71,750\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,027,974</span> (15.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,027,974\u001b[0m (15.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,027,974</span> (15.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,027,974\u001b[0m (15.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='khayyammolana/checkpoints', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=50, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'khayyammolana/checkpoints'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint('khayyammolana/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocabolary_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.Dense(vocabolary_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.load_weights(\"khayyammolana/checkpoints/my_model.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 256)         12032     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, None, 1024)        3938304   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 47)          48175     \n",
      "=================================================================\n",
      "Total params: 3,998,511\n",
      "Trainable params: 3,998,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 23), dtype=int32, numpy=\n",
       "array([[10, 34,  1, 33,  9, 32,  1, 16, 17,  9, 35, 33, 17,  1, 14,  9,\n",
       "        33,  1, 35,  1, 16, 19, 17]], dtype=int32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_generate = 1000\n",
    "first_string = 'به نام خداوند جان و خرد'\n",
    "input_eval = [char2index[s] for s in first_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "input_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "9\n",
      "10\n",
      "17\n",
      "46\n",
      "31\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "32\n",
      "0\n",
      "3\n",
      "33\n",
      "9\n",
      "30\n",
      "34\n",
      "40\n",
      "1\n",
      "14\n",
      "21\n",
      "32\n",
      "1\n",
      "35\n",
      "31\n",
      "46\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "21\n",
      "1\n",
      "10\n",
      "17\n",
      "46\n",
      "17\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "32\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "10\n",
      "19\n",
      "1\n",
      "6\n",
      "28\n",
      "9\n",
      "20\n",
      "1\n",
      "44\n",
      "19\n",
      "17\n",
      "0\n",
      "3\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "10\n",
      "28\n",
      "17\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "17\n",
      "22\n",
      "32\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "22\n",
      "33\n",
      "9\n",
      "21\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "10\n",
      "17\n",
      "9\n",
      "33\n",
      "17\n",
      "1\n",
      "42\n",
      "19\n",
      "16\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "32\n",
      "33\n",
      "1\n",
      "17\n",
      "19\n",
      "1\n",
      "17\n",
      "31\n",
      "46\n",
      "0\n",
      "3\n",
      "45\n",
      "19\n",
      "1\n",
      "33\n",
      "32\n",
      "9\n",
      "20\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "20\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "21\n",
      "16\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "1\n",
      "33\n",
      "46\n",
      "44\n",
      "1\n",
      "35\n",
      "1\n",
      "10\n",
      "17\n",
      "22\n",
      "1\n",
      "20\n",
      "46\n",
      "33\n",
      "1\n",
      "33\n",
      "9\n",
      "33\n",
      "1\n",
      "42\n",
      "19\n",
      "9\n",
      "0\n",
      "3\n",
      "34\n",
      "19\n",
      "1\n",
      "42\n",
      "34\n",
      "1\n",
      "10\n",
      "19\n",
      "1\n",
      "12\n",
      "21\n",
      "35\n",
      "46\n",
      "19\n",
      "1\n",
      "42\n",
      "46\n",
      "33\n",
      "34\n",
      "1\n",
      "31\n",
      "14\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "21\n",
      "16\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "19\n",
      "35\n",
      "15\n",
      "1\n",
      "34\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "6\n",
      "33\n",
      "1\n",
      "9\n",
      "13\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "1\n",
      "10\n",
      "9\n",
      "20\n",
      "46\n",
      "1\n",
      "17\n",
      "16\n",
      "35\n",
      "46\n",
      "22\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "22\n",
      "9\n",
      "17\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "46\n",
      "9\n",
      "33\n",
      "1\n",
      "16\n",
      "35\n",
      "9\n",
      "10\n",
      "1\n",
      "14\n",
      "21\n",
      "12\n",
      "1\n",
      "35\n",
      "1\n",
      "45\n",
      "9\n",
      "34\n",
      "1\n",
      "6\n",
      "33\n",
      "1\n",
      "16\n",
      "31\n",
      "46\n",
      "1\n",
      "14\n",
      "35\n",
      "1\n",
      "10\n",
      "19\n",
      "17\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "0\n",
      "3\n",
      "41\n",
      "46\n",
      "22\n",
      "1\n",
      "6\n",
      "19\n",
      "17\n",
      "1\n",
      "30\n",
      "19\n",
      "23\n",
      "1\n",
      "17\n",
      "46\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "35\n",
      "9\n",
      "1\n",
      "19\n",
      "34\n",
      "9\n",
      "33\n",
      "0\n",
      "3\n",
      "42\n",
      "22\n",
      "32\n",
      "34\n",
      "40\n",
      "1\n",
      "16\n",
      "35\n",
      "33\n",
      "1\n",
      "19\n",
      "9\n",
      "1\n",
      "10\n",
      "29\n",
      "33\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "19\n",
      "46\n",
      "45\n",
      "1\n",
      "9\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "21\n",
      "1\n",
      "45\n",
      "19\n",
      "9\n",
      "20\n",
      "1\n",
      "6\n",
      "10\n",
      "21\n",
      "12\n",
      "1\n",
      "33\n",
      "30\n",
      "22\n",
      "9\n",
      "33\n",
      "1\n",
      "35\n",
      "1\n",
      "13\n",
      "10\n",
      "9\n",
      "10\n",
      "0\n",
      "3\n",
      "42\n",
      "35\n",
      "33\n",
      "44\n",
      "1\n",
      "6\n",
      "35\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "10\n",
      "46\n",
      "16\n",
      "1\n",
      "35\n",
      "1\n",
      "33\n",
      "35\n",
      "0\n",
      "3\n",
      "10\n",
      "9\n",
      "1\n",
      "22\n",
      "32\n",
      "9\n",
      "1\n",
      "9\n",
      "20\n",
      "1\n",
      "16\n",
      "31\n",
      "30\n",
      "1\n",
      "9\n",
      "46\n",
      "33\n",
      "1\n",
      "21\n",
      "35\n",
      "20\n",
      "46\n",
      "1\n",
      "35\n",
      "1\n",
      "17\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "17\n",
      "19\n",
      "1\n",
      "10\n",
      "46\n",
      "9\n",
      "10\n",
      "9\n",
      "33\n",
      "34\n",
      "9\n",
      "46\n",
      "1\n",
      "10\n",
      "46\n",
      "1\n",
      "42\n",
      "33\n",
      "17\n",
      "46\n",
      "1\n",
      "22\n",
      "44\n",
      "21\n",
      "12\n",
      "0\n",
      "3\n",
      "9\n",
      "33\n",
      "17\n",
      "19\n",
      "1\n",
      "6\n",
      "1\n",
      "32\n",
      "9\n",
      "17\n",
      "19\n",
      "1\n",
      "32\n",
      "17\n",
      "34\n",
      "1\n",
      "17\n",
      "9\n",
      "17\n",
      "9\n",
      "33\n",
      "1\n",
      "46\n",
      "44\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "text_generated = ['به نام خداوند جان و خرد']\n",
    "for i in range(500):\n",
    "    predictions = model_2.predict(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "#     predicted_ids = tf.random.categorical(predictions, num_samples=1).numpy()\n",
    "    predicted_ids = np.array(predictions.numpy()).argmax(axis=1).reshape(-1, 1)[-1][0]\n",
    "    print(predicted_ids)\n",
    "    message = np.append(input_eval[0].numpy(), predicted_ids)[1:]\n",
    "    input_eval = tf.expand_dims(message, 0)\n",
    "    text_generated.append(index2char[predicted_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['به نام خداوند جان و خرد',\n",
       " '|در بیان ماند از ابدیل و گم',\n",
       " '|ناقهٔ جسم ولی را بس بدید',\n",
       " '|چون بماند از خبر آغاز کرد',\n",
       " '|گاه بغد از دشمنان این را شناس',\n",
       " '|چون بداند چرخ را من در دلی',\n",
       " '|گر نماز و روز می آرد سخن',\n",
       " '|چون نیک و بدش زین نان چرا',\n",
       " '|هر چه بر تسویر چینه لجت و سخان و روح هست',\n",
       " '|آن اثر می بازی دخویش و دشاد',\n",
       " '|در میان خواب جست و گاه آن خلی جو برد این',\n",
       " '|پیش آرد قرص دین را وا رهان',\n",
       " '|چشمهٔ خون را بفن از ریگ او',\n",
       " '|بس گراز آبست نقشان و ثباب',\n",
       " '|چونک آواز خلق از بیخ و نو',\n",
       " '|با شما از خلق این سوزی و دست',\n",
       " '|در بیابانهای بی چندی شکست',\n",
       " '|اندر آ مادر مده دادان یکی']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(text_generated).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "|در بیان ماند از ابدیل و گم\n",
      "|ناقهٔ جسم ولی را بس بدید\n",
      "|چون بماند از خبر آغاز کرد\n",
      "|گاه بغد از دشمنان این را شناس\n",
      "|چون بداند چرخ را من در دلی\n",
      "|گر نماز و روز می آرد سخن\n",
      "|چون نیک و بدش زین نان چرا\n",
      "|هر چه بر تسویر چینه لجت و سخان و روح هست\n",
      "|آن اثر می بازی دخویش و دشاد\n",
      "|در میان خواب جست و گاه آن خلی جو برد این\n",
      "|پیش آرد قرص دین را وا رهان\n",
      "|چشمهٔ خون را بفن از ریگ او\n",
      "|بس گراز آبست نقشان و ثباب\n",
      "|چونک آواز خلق از بیخ و نو\n",
      "|با شما از خلق این سوزی و دست\n",
      "|در بیابانهای بی چندی شکست\n",
      "|اندر آ مادر مده دادان یکی\n"
     ]
    }
   ],
   "source": [
    "for i in ''.join(text_generated).split('\\n'):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
